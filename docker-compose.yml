# ========================================
# FILENAME: aivlebigproject/docker-compose.yml
# 역할 : 
# ========================================

version: '3.8' # 최신 버전 명시
services:
  my-kafka:
    image: confluentinc/cp-kafka:latest
    container_name: my-kafka
    ports:
      - "9092:9092"   # 클라이언트 통신용
    environment:
      # KRaft 모드 필수 설정
      CLUSTER_ID: "kraft-cluster-01"
      KAFKA_KRAFT_MODE: "true"
      KAFKA_PROCESS_ROLES: "broker,controller"
      KAFKA_NODE_ID: "1"
      # 👇 서비스 이름에 맞게 'my-kafka'로 수정
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@my-kafka:9093"

      # 리스너 설정
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
      # 컨테이너 간 통신 시에는 서비스 이름(my-kafka)을, 외부에서는 localhost를 사용합니다.
      # Java/Python 서비스가 Docker 내부에서 통신하므로 kafka:9092로 설정하는 것이 좋습니다.
      # 👇 다른 컨테이너들이 접속할 주소를 'my-kafka'로 수정
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://my-kafka:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER

      # 기타 필수 설정
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_LOG_RETENTION_HOURS: 168
      KAFKA_LOG_DIRS: "/var/lib/kafka/data"
    volumes:
      - kafka-data:/var/lib/kafka/data

    healthcheck:
      test: ["CMD-SHELL", "kafka-topics --list --bootstrap-server localhost:9092 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

  # Gateway 서비스 추가
  gateway:
    image: adoptopenjdk/maven-openjdk11:latest
    command: mvn spring-boot:run
    working_dir: /usr/src
    depends_on:
      # - servicecontext # 서비스가 실행된 후에 gateway가 실행되도록 설정
      - funeralcontext 
      # - usercontext
      # - memorialcontext
      # - dataanalysis
      - funeralcontext-ai
      # - memorialcontext-ai
      # - dataanalysis-ai
    environment:
      - SPRING_PROFILES_ACTIVE=docker
    ports:
      - "8080:8080" # 외부 8080 포트를 컨테이너 8080 포트로 연결
    volumes:
      - ./gateway:/usr/src # 로컬 gateway 폴더를 컨테이너와 연결
      - ./maven-repo:/root/.m2

  servicecontext:
    # build: ... 를 삭제하고 아래 내용으로 변경
    image: adoptopenjdk/maven-openjdk11:latest
    command: mvn spring-boot:run
    working_dir: /usr/src
    depends_on:
      my-kafka:
        condition: service_healthy # kafka 서비스가 healthy 상태가 될 때까지 기다림
    environment:
      - SPRING_PROFILES_ACTIVE=docker
    env_file: # <-- env : OpenAI API, Azureblob, AzuremySQL, 영상-음악API
      - .env          
    volumes:
      - ./servicecontext:/usr/src
      - ./maven-repo:/root/.m2

  funeralcontext:
    # build: ... 를 삭제하고 아래 내용으로 변경
    image: adoptopenjdk/maven-openjdk11:latest
    command: mvn spring-boot:run
    working_dir: /usr/src
    depends_on:
      my-kafka:
        condition: service_healthy # kafka 서비스가 healthy 상태가 될 때까지 기다림
    environment:
      - SPRING_PROFILES_ACTIVE=docker
    env_file: # <-- env : OpenAI API, Azureblob, AzuremySQL, 영상-음악API
      - .env          
    volumes:
      - ./funeralcontext:/usr/src
      - ./maven-repo:/root/.m2

  # usercontext:
  #   # build: ... 를 삭제하고 아래 내용으로 변경
  #   image: adoptopenjdk/maven-openjdk11:latest
  #   command: mvn spring-boot:run
  #   working_dir: /usr/src
  #   depends_on:
  #     my-kafka:
  #       condition: service_healthy # kafka 서비스가 healthy 상태가 될 때까지 기다림
  #   environment:
  #     - SPRING_PROFILES_ACTIVE=docker   
  #   volumes:
  #     - ./usercontext:/usr/src
  #     - ./maven-repo:/root/.m2

  # memorialcontext:
  #   # build: ... 를 삭제하고 아래 내용으로 변경
  #   image: adoptopenjdk/maven-openjdk11:latest
  #   command: mvn spring-boot:run
  #   working_dir: /usr/src
  #   depends_on:
  #     my-kafka:
  #       condition: service_healthy # kafka 서비스가 healthy 상태가 될 때까지 기다림
  #   environment:
  #     - SPRING_PROFILES_ACTIVE=docker
  #   env_file: # <-- env : OpenAI API, Azureblob, AzuremySQL, 영상-음악API
  #     - .env          
  #   volumes:
  #     - ./memorialcontext:/usr/src
  #     - ./maven-repo:/root/.m2

  # dataanalysis:
  #   # build: ... 를 삭제하고 아래 내용으로 변경
  #   image: adoptopenjdk/maven-openjdk11:latest
  #   command: mvn spring-boot:run
  #   working_dir: /usr/src
  #   depends_on:
  #     my-kafka:
  #       condition: service_healthy # kafka 서비스가 healthy 상태가 될 때까지 기다림
  #   environment:
  #     - SPRING_PROFILES_ACTIVE=docker   
  #   volumes:
  #     - ./dataanalysis:/usr/src
  #     - ./maven-repo:/root/.m2

  funeralcontext-ai:
    # build: ... 를 삭제하고 아래 내용으로 변경
    image: python:3.9-slim # 1. Python 공식 이미지를 직접 사용
    command: sh -c "pip install -r requirements.txt && uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload"
    working_dir: /app
    depends_on:
      my-kafka:
        condition: service_healthy # kafka 서비스가 healthy 상태가 될 때까지 기다림
    env_file: # <-- env : OpenAI API, Azureblob, AzuremySQL, 영상-음악API
      - .env          
    volumes:
      - ./funeralcontext-ai:/app

  # memorialcontext-ai:
  #   # build: ... 를 삭제하고 아래 내용으로 변경
  #   image: python:3.9-slim
  #   command: sh -c "pip install -r requirements.txt && uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload"
  #   working_dir: /app
  #   depends_on:
  #     my-kafka:
  #       condition: service_healthy # kafka 서비스가 healthy 상태가 될 때까지 기다림
  #   env_file: # <-- env : OpenAI API, Azureblob, AzuremySQL, 영상-음악API
  #     - .env          
  #   volumes:
  #     - ./memorialcontext-ai:/app

  # dataanalysis-ai:
  #   # build: ... 를 삭제하고 아래 내용으로 변경
  #   image: python:3.9-slim # 1. Python 공식 이미지를 직접 사용
  #   command: sh -c "pip install -r requirements.txt && uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload"
  #   working_dir: /app
  #   depends_on:
  #     my-kafka:
  #       condition: service_healthy # kafka 서비스가 healthy 상태가 될 때까지 기다림
  #   env_file: # <-- env : OpenAI API, Azureblob, AzuremySQL, 영상-음악API
  #     - .env          
  #   volumes:
  #     - ./dataanalysis-ai:/app

volumes:
  kafka-data:
  maven-repo: # Maven 라이브러리 캐시를 위한 볼륨 추가